"""
éŸ³é¢‘è½¬å½•æœåŠ¡
ä½¿ç”¨å¤šæ¨¡å‹è¿›è¡Œè¯­éŸ³è½¬æ–‡å­—
"""
import os
import logging
import asyncio
from typing import Optional
from types import SimpleNamespace

from backend.core.ai_client import get_asr_model
from backend.config.ai_config import get_asr_config

logger = logging.getLogger(__name__)

_transcribe_semaphore = asyncio.Semaphore(1)


class AudioTranscriber:
    """éŸ³é¢‘è½¬å½•æœåŠ¡"""
    
    def __init__(self):
        """åˆå§‹åŒ–è½¬å½•æœåŠ¡"""
        self.config = get_asr_config()
        self.last_detected_language: Optional[str] = None
    
    async def transcribe_audio(
        self,
        audio_path: str,
        language: Optional[str] = None,
        video_title: str = "",
        video_url: str = "",
        cancel_check: Optional[callable] = None
    ) -> str:
        """
        è½¬å½•éŸ³é¢‘æ–‡ä»¶
        
        Args:
            audio_path: éŸ³é¢‘æ–‡ä»¶è·¯å¾„
            language: æŒ‡å®šè¯­è¨€ï¼ˆå¯é€‰ï¼Œå¦‚æœä¸æŒ‡å®šåˆ™è‡ªåŠ¨æ£€æµ‹ï¼‰
            video_title: è§†é¢‘æ ‡é¢˜ï¼ˆå¯é€‰ï¼‰
            video_url: è§†é¢‘URLï¼ˆå¯é€‰ï¼‰
            
        Returns:
            è½¬å½•æ–‡æœ¬ï¼ˆMarkdownæ ¼å¼ï¼‰
            
        Raises:
            Exception: è½¬å½•å¤±è´¥
        """
        try:
            if not os.path.exists(audio_path):
                raise Exception(f"éŸ³é¢‘æ–‡ä»¶ä¸å­˜åœ¨: {audio_path}")
            
            logger.info(f"å¼€å§‹è½¬å½•éŸ³é¢‘: {audio_path}")
            
            async with _transcribe_semaphore:
                provider = self.config.provider.lower()
                logger.info(f"ğŸ¤– æ­£åœ¨åŠ è½½ ASR æ¨¡å‹: {provider}:{self.config.model}")
                model = get_asr_model()
                logger.info("âœ… ASR æ¨¡å‹åŠ è½½å®Œæˆ")
                
                if provider == "whisper":
                    segments, info = await asyncio.to_thread(
                        self._do_whisper_transcribe,
                        model,
                        audio_path,
                        language
                    )
                elif provider == "funasr":
                    segments, info = await asyncio.to_thread(
                        self._do_funasr_transcribe,
                        model,
                        audio_path,
                        language
                    )
                elif provider == "qwen3":
                    segments, info = await asyncio.to_thread(
                        self._do_qwen_transcribe,
                        model,
                        audio_path,
                        language
                    )
                else:
                    raise Exception(f"ä¸æ”¯æŒçš„ASRæä¾›æ–¹: {self.config.provider}")
            
            # ä¿å­˜æ£€æµ‹åˆ°çš„è¯­è¨€
            detected_language = getattr(info, "language", None) or language or "unknown"
            language_probability = getattr(info, "language_probability", None)
            if language_probability is None:
                language_probability = 0.0
            self.last_detected_language = detected_language
            logger.info(f"æ£€æµ‹åˆ°çš„è¯­è¨€: {detected_language}")
            logger.info(f"è¯­è¨€æ£€æµ‹æ¦‚ç‡: {language_probability:.2f}")
            
            # ç»„è£…è½¬å½•ç»“æœ
            transcript_text = self._format_transcript(
                segments,
                detected_language,
                language_probability,
                video_title,
                video_url
            )
            
            logger.info("è½¬å½•å®Œæˆ")
            return transcript_text
            
        except Exception as e:
            logger.error(f"è½¬å½•å¤±è´¥: {str(e)}")
            raise Exception(f"è½¬å½•å¤±è´¥: {str(e)}")
    
    def _do_whisper_transcribe(self, model, audio_path: str, language: Optional[str]):
        """
        æ‰§è¡Œå®é™…çš„è½¬å½•æ“ä½œï¼ˆåœ¨çº¿ç¨‹ä¸­è¿è¡Œï¼‰
        
        Args:
            model: Whisperæ¨¡å‹å®ä¾‹
            audio_path: éŸ³é¢‘æ–‡ä»¶è·¯å¾„
            language: æŒ‡å®šè¯­è¨€
            
        Returns:
            (segments, info) è½¬å½•ç‰‡æ®µå’Œä¿¡æ¯
        """
        whisper_config = self.config.whisper
        segments_generator, info = model.transcribe(
            audio_path,
            language=language,
            beam_size=whisper_config.beam_size,
            best_of=whisper_config.best_of,
            temperature=whisper_config.temperature,
            # VADå‚æ•°ï¼ˆé™ä½é™éŸ³/å™ªéŸ³å¯¼è‡´çš„é‡å¤ï¼‰
            vad_filter=whisper_config.vad_filter,
            vad_parameters={
                "min_silence_duration_ms": whisper_config.min_silence_duration_ms,
                "speech_pad_ms": whisper_config.speech_pad_ms
            },
            # é˜ˆå€¼å‚æ•°
            no_speech_threshold=whisper_config.no_speech_threshold,
            compression_ratio_threshold=whisper_config.compression_ratio_threshold,
            log_prob_threshold=whisper_config.log_prob_threshold,
            # é¿å…é”™è¯¯ç´¯ç§¯å¯¼è‡´çš„è¿ç¯é‡å¤
            condition_on_previous_text=whisper_config.condition_on_previous_text
        )
        
        # æ”¶é›†æ‰€æœ‰segmentå¹¶æ‰“å°æ—¶é—´æ®µä¿¡æ¯
        segments_list = []
        segment_count = 0
        
        logger.info("=" * 60)
        logger.info("ğŸ¬ å¼€å§‹é€æ®µå¤„ç†éŸ³é¢‘")
        logger.info("=" * 60)
        
        for segment in segments_generator:
            segment_count += 1
            start_time = self._format_time(segment.start)
            end_time = self._format_time(segment.end)
            duration = segment.end - segment.start
            text_preview = segment.text.strip()[:50] + "..." if len(segment.text.strip()) > 50 else segment.text.strip()
            
            # æ‰“å°æ¯ä¸ªsegmentçš„è¯¦ç»†ä¿¡æ¯
            logger.info(f"ğŸ“ ç‰‡æ®µ #{segment_count:03d} | {start_time} â†’ {end_time} | æ—¶é•¿: {duration:.1f}s")
            logger.info(f"   å†…å®¹: {text_preview}")
            logger.info("-" * 60)
            
            segments_list.append(segment)
        
        logger.info("=" * 60)
        logger.info(f"âœ… å¤„ç†å®Œæˆï¼å…± {segment_count} ä¸ªç‰‡æ®µ")
        logger.info("=" * 60)
        
        return segments_list, info

    def _do_funasr_transcribe(self, model, audio_path: str, language: Optional[str]):
        model_id = self.config.model
        result = model.generate(
            input=[audio_path],
            cache={},
            language=language or "auto",
            batch_size=1
        )
            
        segments, detected_language = self._parse_funasr_result(result, language)
        info = SimpleNamespace(
            language=detected_language,
            language_probability=0.0
        )
        return segments, info

    def _do_qwen_transcribe(self, model, audio_path: str, language: Optional[str]):
        results = model.transcribe(
            audio=audio_path,
            language=language
        )
        segments, detected_language = self._parse_qwen_result(results, language)
        info = SimpleNamespace(
            language=detected_language,
            language_probability=0.0
        )
        return segments, info

    def _parse_funasr_result(self, result, fallback_language: Optional[str]):
        detected_language = fallback_language or "unknown"
        if isinstance(result, list) and result:
            item = result[0] if isinstance(result[0], dict) else {}
            detected_language = item.get("language") or item.get("lang") or detected_language
            sentence_info = item.get("sentence_info") or item.get("sentences")
            if sentence_info:
                segments = []
                for sentence in sentence_info:
                    text = (sentence.get("text") or "").strip()
                    if not text:
                        continue
                    start = self._normalize_timestamp(sentence.get("start") or sentence.get("start_time"), "ms")
                    end = self._normalize_timestamp(sentence.get("end") or sentence.get("end_time"), "ms")
                    segments.append(SimpleNamespace(start=start, end=end, text=text))
                if segments:
                    return segments, detected_language
            text = (item.get("text") or "").strip()
            if text:
                return self._build_single_segment(text), detected_language
        return self._build_single_segment(""), detected_language

    def _parse_qwen_result(self, results, fallback_language: Optional[str]):
        detected_language = fallback_language or "unknown"
        if isinstance(results, list) and results:
            res = results[0]
            if isinstance(res, dict):
                detected_language = res.get("language") or detected_language
                segments_data = res.get("segments")
                text = res.get("text")
            else:
                detected_language = getattr(res, "language", None) or detected_language
                segments_data = getattr(res, "segments", None)
                text = getattr(res, "text", None)
            if segments_data:
                segments = []
                for seg in segments_data:
                    if isinstance(seg, dict):
                        seg_text = seg.get("text")
                        start = seg.get("start_time", seg.get("start"))
                        end = seg.get("end_time", seg.get("end"))
                    else:
                        seg_text = getattr(seg, "text", None)
                        start = getattr(seg, "start_time", None) or getattr(seg, "start", None)
                        end = getattr(seg, "end_time", None) or getattr(seg, "end", None)
                    if not seg_text:
                        continue
                    segments.append(SimpleNamespace(
                        start=self._normalize_timestamp(start, "s"),
                        end=self._normalize_timestamp(end, "s"),
                        text=seg_text.strip()
                    ))
                if segments:
                    return segments, detected_language
            if text:
                return self._build_single_segment(str(text)), detected_language
        return self._build_single_segment(""), detected_language

    def _build_single_segment(self, text: str):
        return [SimpleNamespace(start=0.0, end=0.0, text=text)]

    def _normalize_timestamp(self, value, unit: str) -> float:
        if value is None:
            return 0.0
        try:
            number = float(value)
        except (TypeError, ValueError):
            return 0.0
        if unit == "ms":
            return number / 1000.0
        return number
    
    def _format_transcript(
        self,
        segments,
        detected_language: str,
        language_probability: float,
        video_title: str = "",
        video_url: str = ""
    ) -> str:
        """
        æ ¼å¼åŒ–è½¬å½•ç»“æœä¸ºMarkdown
        
        Args:
            segments: è½¬å½•ç‰‡æ®µ
            detected_language: æ£€æµ‹åˆ°çš„è¯­è¨€
            language_probability: è¯­è¨€æ£€æµ‹æ¦‚ç‡
            video_title: è§†é¢‘æ ‡é¢˜
            video_url: è§†é¢‘URL
            
        Returns:
            æ ¼å¼åŒ–çš„Markdownæ–‡æœ¬
        """
        from datetime import datetime
        
        # è¯­è¨€åç§°æ˜ å°„
        language_names = {
            'zh': 'ä¸­æ–‡',
            'en': 'English',
            'ja': 'æ—¥æœ¬èª',
            'ko': 'í•œêµ­ì–´',
            'es': 'EspaÃ±ol',
            'fr': 'FranÃ§ais',
            'de': 'Deutsch',
            'it': 'Italiano',
            'pt': 'PortuguÃªs',
            'ru': 'Ğ ÑƒÑÑĞºĞ¸Ğ¹',
            'ar': 'Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©',
            'hi': 'à¤¹à¤¿à¤¨à¥à¤¦à¥€',
            'th': 'à¹„à¸—à¸¢',
            'vi': 'Tiáº¿ng Viá»‡t',
            'tr': 'TÃ¼rkÃ§e',
            'pl': 'Polski',
            'nl': 'Nederlands',
            'sv': 'Svenska',
            'da': 'Dansk',
            'no': 'Norsk'
        }
        
        lang_display = language_names.get(detected_language, detected_language)
        
        lines = []
        lines.append("# è§†é¢‘è½¬å½•æ–‡æœ¬")
        lines.append("")
        
        # è§†é¢‘ä¿¡æ¯å—
        if video_title or video_url:
            lines.append(f"> ğŸ“¹ **è§†é¢‘æ ‡é¢˜ï¼š** {video_title or 'æœªçŸ¥'}")
            lines.append("> ")
            lines.append(f"> ğŸŒ **æ£€æµ‹è¯­è¨€ï¼š** {lang_display} ({detected_language})")
            lines.append("> ")
            if video_url:
                lines.append(f"> ğŸ”— **è§†é¢‘æ¥æºï¼š** [ç‚¹å‡»è§‚çœ‹]({video_url})")
            lines.append("")
            lines.append("---")
            lines.append("")
        
        lines.append("## ğŸ“ è½¬å½•å†…å®¹")
        lines.append("")
        
        # æ·»åŠ æ—¶é—´æˆ³å’Œæ–‡æœ¬
        for segment in segments:
            start_time = self._format_time(segment.start)
            end_time = self._format_time(segment.end)
            text = segment.text.strip()
            
            lines.append(f"**{start_time} - {end_time}**  ")
            lines.append(text)
            lines.append("")
        
        lines.append("---")
        lines.append("")
        
        # é¡µè„šä¿¡æ¯
        current_time = datetime.now().strftime("%Y-%m-%d %H:%M")
        lines.append(f"*è½¬å½•æ—¶é—´ï¼š{current_time}*  ")
        lines.append("*ç”± ViNote AI è‡ªåŠ¨ç”Ÿæˆ*")
        
        return "\n".join(lines)
    
    def _format_time(self, seconds: float) -> str:
        """
        å°†ç§’æ•°è½¬æ¢ä¸ºæ—¶åˆ†ç§’æ ¼å¼
        
        Args:
            seconds: ç§’æ•°
            
        Returns:
            æ ¼å¼åŒ–çš„æ—¶é—´å­—ç¬¦ä¸² (HH:MM:SS æˆ– MM:SS)
        """
        hours = int(seconds // 3600)
        minutes = int((seconds % 3600) // 60)
        secs = int(seconds % 60)
        
        if hours > 0:
            return f"{hours:02d}:{minutes:02d}:{secs:02d}"
        else:
            return f"{minutes:02d}:{secs:02d}"
    
    def get_detected_language(self, transcript_text: Optional[str] = None) -> Optional[str]:
        """
        è·å–æ£€æµ‹åˆ°çš„è¯­è¨€
        
        Args:
            transcript_text: è½¬å½•æ–‡æœ¬ï¼ˆå¯é€‰ï¼Œç”¨äºä»æ–‡æœ¬ä¸­æå–è¯­è¨€ä¿¡æ¯ï¼‰
            
        Returns:
            æ£€æµ‹åˆ°çš„è¯­è¨€ä»£ç 
        """
        # å¦‚æœæœ‰ä¿å­˜çš„è¯­è¨€ï¼Œç›´æ¥è¿”å›
        if self.last_detected_language:
            return self.last_detected_language
        
        # å¦‚æœæä¾›äº†è½¬å½•æ–‡æœ¬ï¼Œå°è¯•ä»ä¸­æå–è¯­è¨€ä¿¡æ¯
        if transcript_text and "**Detected Language:**" in transcript_text:
            lines = transcript_text.split('\n')
            for line in lines:
                if "**Detected Language:**" in line:
                    lang = line.split(":")[-1].strip()
                    return lang
        
        return None
    
    def is_available(self) -> bool:
        """
        æ£€æŸ¥è½¬å½•æœåŠ¡æ˜¯å¦å¯ç”¨
        
        Returns:
            True if Whisperæ¨¡å‹å¯ç”¨
        """
        try:
            model = get_asr_model()
            return model is not None
        except Exception as e:
            logger.error(f"æ£€æŸ¥ASRæ¨¡å‹å¯ç”¨æ€§å¤±è´¥: {e}")
            return False
    
    @staticmethod
    def get_supported_languages() -> list:
        """
        è·å–æ”¯æŒçš„è¯­è¨€åˆ—è¡¨
        
        Returns:
            æ”¯æŒçš„è¯­è¨€ä»£ç åˆ—è¡¨
        """
        return [
            "zh", "en", "ja", "ko", "es", "fr", "de", "it", "pt", "ru",
            "ar", "hi", "th", "vi", "tr", "pl", "nl", "sv", "da", "no"
        ]
