"""
è§†é¢‘ä¸‹è½½æœåŠ¡
ä½¿ç”¨yt-dlpä¸‹è½½è§†é¢‘å¹¶è½¬æ¢ä¸ºéŸ³é¢‘ï¼Œæ”¯æŒå­—å¹•æå–
"""
import os
import re
import yt_dlp
import logging
import asyncio
import subprocess
import shlex
import uuid
from pathlib import Path
from typing import Tuple, Optional, List

from backend.config.settings import get_settings

logger = logging.getLogger(__name__)
settings = get_settings()


class VideoDownloader:
    """è§†é¢‘ä¸‹è½½æœåŠ¡"""

    def __init__(self):
        """åˆå§‹åŒ–yt-dlpé…ç½®"""
        # è·å–cookiesæ–‡ä»¶è·¯å¾„ï¼ˆé¡¹ç›®æ ¹ç›®å½•ï¼‰
        self.project_root = Path(__file__).parent.parent.parent
        self.bilibili_cookies = self.project_root / "bilibili_cookies.txt"
        
        # åŸºç¡€é…ç½®ï¼ˆä¸å« cookiesï¼‰- ç§»é™¤å¯èƒ½å¯¼è‡´YouTubeé—®é¢˜çš„http_headers
        self.base_ydl_opts = {
            'format': 'bestaudio/best',  # ä¼˜å…ˆä¸‹è½½æœ€ä½³éŸ³é¢‘æº
            'outtmpl': '%(title)s.%(ext)s',
            'retries': 10,  # å¢åŠ é‡è¯•æ¬¡æ•°
            'fragment_retries': 10,
            # YouTube 403 ä¿®å¤ï¼šä½¿ç”¨ android_vr å®¢æˆ·ç«¯ç»•è¿‡é™åˆ¶ (fix #4 #5)
            'extractor_args': {
                'youtube': {
                    'player_client': ['android_vr', 'web']
                }
            },
            'postprocessors': [{
                'key': 'FFmpegExtractAudio',
                # ç›´æ¥åœ¨æå–é˜¶æ®µè½¬æ¢ä¸ºå•å£°é“ 16kï¼ˆç©ºé—´å°ä¸”ç¨³å®šï¼‰
                'preferredcodec': 'm4a',
                'preferredquality': '192'
            }],
            # å…¨å±€FFmpegå‚æ•°ï¼šå•å£°é“ + 16k é‡‡æ ·ç‡ + faststart
            'postprocessor_args': ['-ac', '1', '-ar', '16000', '-movflags', '+faststart'],
            'prefer_ffmpeg': True,
            'quiet': True,
            'no_warnings': True,
            'noplaylist': True,  # å¼ºåˆ¶åªä¸‹è½½å•ä¸ªè§†é¢‘ï¼Œä¸ä¸‹è½½æ’­æ”¾åˆ—è¡¨
        }
    
    def _get_cookies_for_url(self, url: str) -> str:
        """æ ¹æ® URL è·å–å¯¹åº”çš„ cookies æ–‡ä»¶è·¯å¾„"""
        # ä»…Bç«™ä½¿ç”¨ cookiesï¼ŒYouTube ä¸ä½¿ç”¨ï¼ˆé¿å…è®¤è¯é—®é¢˜ï¼‰
        if 'bilibili.com' in url or 'b23.tv' in url:
            if self.bilibili_cookies.exists():
                logger.info(f"ä½¿ç”¨ Bç«™ cookies: {self.bilibili_cookies}")
                return str(self.bilibili_cookies)
        
        return None

    async def download_video_audio(
        self,
        url: str,
        output_dir: Optional[Path] = None
    ) -> Tuple[str, str]:
        """
        ä¸‹è½½è§†é¢‘å¹¶è½¬æ¢ä¸ºéŸ³é¢‘æ ¼å¼

        Args:
            url: è§†é¢‘URL
            output_dir: è¾“å‡ºç›®å½•ï¼Œé»˜è®¤ä½¿ç”¨é…ç½®çš„TEMP_DIR

        Returns:
            (éŸ³é¢‘æ–‡ä»¶è·¯å¾„, è§†é¢‘æ ‡é¢˜)

        Raises:
            Exception: ä¸‹è½½æˆ–è½¬æ¢å¤±è´¥
        """
        if output_dir is None:
            output_dir = settings.TEMP_DIR

        try:
            # åˆ›å»ºè¾“å‡ºç›®å½•
            output_dir.mkdir(exist_ok=True)

            # ç”Ÿæˆå”¯ä¸€çš„æ–‡ä»¶å
            unique_id = str(uuid.uuid4())[:8]
            output_template = str(output_dir / f"audio_{unique_id}.%(ext)s")

            # æ›´æ–°yt-dlpé€‰é¡¹
            ydl_opts = self.base_ydl_opts.copy()
            ydl_opts['outtmpl'] = output_template
            
            # æ ¹æ® URL é€‰æ‹©å¯¹åº”çš„ cookies
            cookies_file = self._get_cookies_for_url(url)
            if cookies_file:
                ydl_opts['cookiefile'] = cookies_file

            logger.info(f"ğŸ“¥ å¼€å§‹æå–éŸ³é¢‘: {url[:60]}...")

            # åœ¨çº¿ç¨‹æ± ä¸­æ‰§è¡Œyt-dlpæ“ä½œï¼ˆé¿å…é˜»å¡äº‹ä»¶å¾ªç¯ï¼‰
            with yt_dlp.YoutubeDL(ydl_opts) as ydl:
                # è·å–è§†é¢‘ä¿¡æ¯
                info = await asyncio.to_thread(ydl.extract_info, url, False)
                video_title = info.get('title', 'unknown')
                expected_duration = info.get('duration') or 0
                logger.info(f"ğŸ¬ è§†é¢‘æ ‡é¢˜: {video_title}")

                # ä¸‹è½½è§†é¢‘
                await asyncio.to_thread(ydl.download, [url])

            # æŸ¥æ‰¾ç”Ÿæˆçš„m4aæ–‡ä»¶
            audio_file = str(output_dir / f"audio_{unique_id}.m4a")

            if not os.path.exists(audio_file):
                # å¦‚æœm4aæ–‡ä»¶ä¸å­˜åœ¨ï¼ŒæŸ¥æ‰¾å…¶ä»–éŸ³é¢‘æ ¼å¼
                for ext in ['webm', 'mp4', 'mp3', 'wav']:
                    potential_file = str(output_dir / f"audio_{unique_id}.{ext}")
                    if os.path.exists(potential_file):
                        audio_file = potential_file
                        break
                else:
                    raise Exception("æœªæ‰¾åˆ°ä¸‹è½½çš„éŸ³é¢‘æ–‡ä»¶")

            # æ ¡éªŒæ—¶é•¿ï¼Œå¦‚æœå’Œæºè§†é¢‘å·®å¼‚è¾ƒå¤§ï¼Œå°è¯•ä¸€æ¬¡ffmpegè§„èŒƒåŒ–é‡å°è£…
            audio_file = await self._verify_and_fix_audio(
                audio_file,
                expected_duration,
                output_dir,
                unique_id
            )

            logger.info(f"âœ… éŸ³é¢‘æå–å®Œæˆ")
            return audio_file, video_title

        except Exception as e:
            logger.error(f"âŒ éŸ³é¢‘æå–å¤±è´¥: {str(e)}")
            raise Exception(f"éŸ³é¢‘æå–å¤±è´¥: {str(e)}")

    async def extract_subtitles(
        self,
        url: str,
        output_dir: Optional[Path] = None,
        preferred_langs: Optional[List[str]] = None,
    ) -> Tuple[Optional[str], Optional[str]]:
        """
        ä»è§†é¢‘ä¸­æå–å­—å¹•ï¼ˆä¼˜å…ˆäººå·¥å­—å¹•ï¼Œå…¶æ¬¡AI/è‡ªåŠ¨å­—å¹•ï¼‰

        æ”¯æŒ YouTubeã€Bilibili ç­‰å¹³å°ã€‚Bç«™å­—å¹•ä»¥ ai-zh/ai-en ç­‰å½¢å¼
        å­˜åœ¨äº subtitles å­—æ®µä¸­ï¼Œä¸”æ•°æ®ç›´æ¥å†…åµŒåœ¨ info['subtitles'] çš„ data å­—æ®µã€‚

        Args:
            url: è§†é¢‘URL
            output_dir: è¾“å‡ºç›®å½•
            preferred_langs: ä¼˜å…ˆè¯­è¨€åˆ—è¡¨ï¼Œå¦‚ ['zh', 'en', 'ja']

        Returns:
            (å­—å¹•æ–‡æœ¬, è§†é¢‘æ ‡é¢˜) â€” å¦‚æœæ— å­—å¹•åˆ™å­—å¹•æ–‡æœ¬ä¸º None
        """
        if output_dir is None:
            output_dir = settings.TEMP_DIR

        output_dir.mkdir(exist_ok=True)

        if preferred_langs is None:
            preferred_langs = ['zh-Hans', 'zh-Hant', 'zh', 'en', 'ja', 'ko']

        try:
            # ç¬¬ä¸€æ­¥ï¼šè·å–è§†é¢‘ä¿¡æ¯ï¼Œæ£€æŸ¥å¯ç”¨å­—å¹•
            # æ³¨æ„ï¼šå¿…é¡»å¯ç”¨ writesubtitles/writeautomaticsubï¼Œå¦åˆ™ yt-dlp ä¸ä¼šæ‹‰å–å­—å¹•ä¿¡æ¯
            info_opts = {
                'quiet': True,
                'no_warnings': True,
                'skip_download': True,
                'writesubtitles': True,
                'writeautomaticsub': True,
                'allsubtitles': True,
                'noplaylist': True,  # åˆé›†åªå–å•ä¸ªè§†é¢‘ï¼Œé¿å…éå†æ‰€æœ‰åˆ†På¯¼è‡´å¡æ­»
            }
            
            cookies_file = self._get_cookies_for_url(url)
            if cookies_file:
                info_opts['cookiefile'] = cookies_file

            with yt_dlp.YoutubeDL(info_opts) as ydl:
                info = await asyncio.to_thread(ydl.extract_info, url, False)

            manual_subs = info.get('subtitles') or {}
            auto_subs = info.get('automatic_captions') or {}
            video_title = info.get('title', 'unknown')

            # é€‰æ‹©æœ€ä½³å­—å¹•ï¼šä¼˜å…ˆäººå·¥å­—å¹•
            chosen_lang, is_auto, sub_source_dict = self._choose_best_subtitle(
                manual_subs, auto_subs, preferred_langs
            )

            if not chosen_lang:
                logger.info(f"è§†é¢‘ '{video_title}' æ— å¯ç”¨å­—å¹•")
                return None, video_title

            sub_source = "AIç”Ÿæˆ" if chosen_lang.startswith('ai-') else ("è‡ªåŠ¨ç”Ÿæˆ" if is_auto else "äººå·¥")
            logger.info(f"ğŸ“„ æ‰¾åˆ°{sub_source}å­—å¹•: {chosen_lang}")

            # ç¬¬äºŒæ­¥ï¼šå°è¯•ä» info å†…åµŒæ•°æ®ä¸­ç›´æ¥è¯»å–å­—å¹•ï¼ˆBç«™ç­‰å¹³å°ï¼‰
            subtitle_text = self._try_extract_inline_subtitle(sub_source_dict, chosen_lang)
            
            if not subtitle_text:
                # å†…åµŒæ•°æ®ä¸å¯ç”¨ï¼Œé€šè¿‡ä¸‹è½½å­—å¹•æ–‡ä»¶è·å–
                unique_id = str(uuid.uuid4())[:8]
                sub_output = str(output_dir / f"sub_{unique_id}")

                sub_opts = {
                    'quiet': True,
                    'no_warnings': True,
                    'skip_download': True,
                    'writesubtitles': not is_auto,
                    'writeautomaticsub': is_auto,
                    'subtitleslangs': [chosen_lang],
                    'subtitlesformat': 'srt/vtt/ass/best',
                    'outtmpl': sub_output,
                    'noplaylist': True,
                }
                
                if cookies_file:
                    sub_opts['cookiefile'] = cookies_file

                with yt_dlp.YoutubeDL(sub_opts) as ydl:
                    await asyncio.to_thread(ydl.download, [url])

                # æŸ¥æ‰¾ä¸‹è½½çš„å­—å¹•æ–‡ä»¶
                sub_file = self._find_subtitle_file(output_dir, f"sub_{unique_id}")
                if not sub_file:
                    logger.warning("å­—å¹•ä¸‹è½½åæœªæ‰¾åˆ°æ–‡ä»¶")
                    return None

                subtitle_text = self._parse_subtitle_file(sub_file)

                # æ¸…ç†å­—å¹•æ–‡ä»¶
                try:
                    os.remove(sub_file)
                except Exception:
                    pass

            if not subtitle_text or len(subtitle_text.strip()) < 10:
                logger.warning("å­—å¹•å†…å®¹ä¸ºç©ºæˆ–è¿‡çŸ­")
                return None, video_title

            logger.info(f"âœ… å­—å¹•æå–æˆåŠŸï¼ˆ{sub_source}ï¼Œ{chosen_lang}ï¼‰ï¼Œå…± {len(subtitle_text)} å­—ç¬¦")
            return subtitle_text, video_title

        except Exception as e:
            logger.warning(f"å­—å¹•æå–å¤±è´¥: {e}")
            return None, None

    def _try_extract_inline_subtitle(self, source_dict: dict, lang: str) -> Optional[str]:
        """
        å°è¯•ä» yt-dlp info ä¸­ç›´æ¥è¯»å–å†…åµŒå­—å¹•æ•°æ®
        
        Bç«™ç­‰å¹³å°çš„å­—å¹•æ•°æ®ç›´æ¥å­˜åœ¨ subtitles[lang][0]['data'] ä¸­ï¼Œ
        æ— éœ€é¢å¤–ä¸‹è½½ã€‚
        """
        try:
            formats = source_dict.get(lang)
            if not formats:
                return None
            
            for fmt in formats:
                data = fmt.get('data')
                if data and isinstance(data, str) and len(data) > 10:
                    ext = fmt.get('ext', 'srt')
                    logger.info(f"ğŸ“„ ä»å†…åµŒæ•°æ®è¯»å–å­—å¹•ï¼ˆ{ext}æ ¼å¼ï¼Œ{len(data)} å­—ç¬¦ï¼‰")
                    
                    if ext == 'srt':
                        return self._parse_srt(data)
                    elif ext == 'vtt':
                        return self._parse_vtt(data)
                    elif ext == 'ass' or ext == 'ssa':
                        return self._parse_ass(data)
                    else:
                        # å°è¯•è‡ªåŠ¨æ£€æµ‹
                        if 'WEBVTT' in data[:50]:
                            return self._parse_vtt(data)
                        else:
                            return self._parse_srt(data)
            
            return None
        except Exception as e:
            logger.warning(f"è¯»å–å†…åµŒå­—å¹•æ•°æ®å¤±è´¥: {e}")
            return None

    def _choose_best_subtitle(
        self,
        manual_subs: dict,
        auto_subs: dict,
        preferred_langs: List[str],
    ) -> Tuple[Optional[str], bool, dict]:
        """
        é€‰æ‹©æœ€ä½³å­—å¹•è¯­è¨€
        
        æ”¯æŒæ ‡å‡†è¯­è¨€ç ï¼ˆzh, enï¼‰å’Œå¸¦å‰ç¼€çš„è¯­è¨€ç ï¼ˆai-zh, ai-en ç­‰Bç«™æ ¼å¼ï¼‰
        
        Returns:
            (è¯­è¨€ä»£ç , æ˜¯å¦ä¸ºè‡ªåŠ¨å­—å¹•, æ¥æºå­—å…¸)
        """
        # æ’é™¤å¼¹å¹•ï¼ˆdanmakuï¼‰
        filtered_manual = {k: v for k, v in manual_subs.items() if k != 'danmaku'}
        
        def _match_lang(available_langs: dict, lang: str) -> Optional[str]:
            """åœ¨å¯ç”¨è¯­è¨€ä¸­æŸ¥æ‰¾åŒ¹é…é¡¹"""
            # ç²¾ç¡®åŒ¹é…
            if lang in available_langs:
                return lang
            # å‰ç¼€åŒ¹é…: zh åŒ¹é… zh-Hans, zh-Hant ç­‰
            for avail in available_langs:
                if avail.startswith(lang) or avail.startswith(f'{lang}-'):
                    return avail
            # AIå‰ç¼€åŒ¹é…: zh åŒ¹é… ai-zhï¼ˆBç«™æ ¼å¼ï¼‰
            ai_key = f'ai-{lang}'
            if ai_key in available_langs:
                return ai_key
            # AIå‰ç¼€æ¨¡ç³ŠåŒ¹é…: zh åŒ¹é… ai-zh-Hans ç­‰
            for avail in available_langs:
                if avail.startswith(ai_key):
                    return avail
            return None
        
        # ä¼˜å…ˆä»äººå·¥å­—å¹•ä¸­æŸ¥æ‰¾ï¼ˆæ’é™¤ ai- å‰ç¼€çš„ï¼Œé‚£äº›æ˜¯AIç”Ÿæˆçš„ï¼‰
        real_manual = {k: v for k, v in filtered_manual.items() if not k.startswith('ai-')}
        for lang in preferred_langs:
            found = _match_lang(real_manual, lang)
            if found:
                return found, False, filtered_manual

        # å…¶æ¬¡ä»äººå·¥å­—å¹•ä¸­æŸ¥æ‰¾AIç”Ÿæˆçš„ï¼ˆBç«™ ai-zh ç­‰åœ¨ subtitles ä¸­ï¼‰
        ai_manual = {k: v for k, v in filtered_manual.items() if k.startswith('ai-')}
        for lang in preferred_langs:
            found = _match_lang(ai_manual, lang)
            if found:
                return found, False, filtered_manual

        # å†ä»è‡ªåŠ¨å­—å¹•ï¼ˆautomatic_captionsï¼‰ä¸­æŸ¥æ‰¾
        for lang in preferred_langs:
            found = _match_lang(auto_subs, lang)
            if found:
                return found, True, auto_subs

        # æœ€åï¼Œå¦‚æœæœ‰ä»»ä½•äººå·¥å­—å¹•ï¼ˆéå¼¹å¹•ï¼‰ï¼Œå–ç¬¬ä¸€ä¸ª
        if filtered_manual:
            first_lang = next(iter(filtered_manual))
            return first_lang, False, filtered_manual

        # å¦‚æœæœ‰ä»»ä½•è‡ªåŠ¨å­—å¹•ï¼Œå–ç¬¬ä¸€ä¸ª
        if auto_subs:
            first_lang = next(iter(auto_subs))
            return first_lang, True, auto_subs

        return None, False, {}

    def _find_subtitle_file(self, directory: Path, prefix: str) -> Optional[str]:
        """æŸ¥æ‰¾å­—å¹•æ–‡ä»¶"""
        sub_extensions = ['.srt', '.vtt', '.ass', '.ssa', '.sub', '.json3']
        for f in directory.iterdir():
            if f.stem.startswith(prefix) or prefix in f.stem:
                if f.suffix.lower() in sub_extensions:
                    return str(f)
        # æ›´å®½æ³›çš„åŒ¹é…
        for f in directory.iterdir():
            if prefix in f.name and f.is_file():
                return str(f)
        return None

    def _parse_subtitle_file(self, filepath: str) -> Optional[str]:
        """
        è§£æå­—å¹•æ–‡ä»¶ä¸ºå¸¦æ—¶é—´æˆ³çš„æ–‡æœ¬
        
        æ”¯æŒ SRTã€VTT æ ¼å¼
        """
        try:
            with open(filepath, 'r', encoding='utf-8') as f:
                content = f.read()
        except UnicodeDecodeError:
            try:
                with open(filepath, 'r', encoding='utf-8-sig') as f:
                    content = f.read()
            except Exception:
                return None

        ext = Path(filepath).suffix.lower()

        if ext == '.srt':
            return self._parse_srt(content)
        elif ext == '.vtt':
            return self._parse_vtt(content)
        elif ext == '.ass' or ext == '.ssa':
            return self._parse_ass(content)
        else:
            # å°è¯•è‡ªåŠ¨æ£€æµ‹æ ¼å¼
            if 'WEBVTT' in content[:50]:
                return self._parse_vtt(content)
            elif re.search(r'\d+\s*\n\d{2}:\d{2}:\d{2}', content[:200]):
                return self._parse_srt(content)
            else:
                return self._parse_srt(content)

    def _parse_srt(self, content: str) -> str:
        """è§£æ SRT å­—å¹•"""
        segments = []
        # SRT æ ¼å¼: åºå·\næ—¶é—´-->æ—¶é—´\næ–‡æœ¬\n\n
        pattern = re.compile(
            r'(\d+)\s*\n'
            r'(\d{2}:\d{2}:\d{2}[,\.]\d{3})\s*-->\s*(\d{2}:\d{2}:\d{2}[,\.]\d{3})\s*\n'
            r'((?:(?!\n\n|\d+\s*\n\d{2}:\d{2}:\d{2}).)+)',
            re.DOTALL
        )
        
        for match in pattern.finditer(content):
            start_str = match.group(2).replace(',', '.')
            end_str = match.group(3).replace(',', '.')
            text = match.group(4).strip()
            # å»é™¤ HTML æ ‡ç­¾
            text = re.sub(r'<[^>]+>', '', text)
            text = text.replace('\n', ' ').strip()
            if text:
                start_sec = self._timestamp_to_seconds(start_str)
                end_sec = self._timestamp_to_seconds(end_str)
                segments.append((start_sec, end_sec, text))

        return self._merge_and_format_segments(segments)

    def _parse_vtt(self, content: str) -> str:
        """è§£æ VTT å­—å¹•"""
        segments = []
        # ç§»é™¤ VTT å¤´éƒ¨
        content = re.sub(r'^WEBVTT.*?\n\n', '', content, flags=re.DOTALL)
        # ç§»é™¤æ ·å¼å—
        content = re.sub(r'STYLE\s*\n.*?\n\n', '', content, flags=re.DOTALL)
        # ç§»é™¤ NOTE å—
        content = re.sub(r'NOTE\s*\n.*?\n\n', '', content, flags=re.DOTALL)

        pattern = re.compile(
            r'(?:\d+\s*\n)?'  # å¯é€‰çš„åºå·
            r'(\d{2}:\d{2}:\d{2}\.\d{3}|\d{2}:\d{2}\.\d{3})\s*-->\s*'
            r'(\d{2}:\d{2}:\d{2}\.\d{3}|\d{2}:\d{2}\.\d{3})'
            r'(?:\s+[^\n]*)?\s*\n'  # å¯é€‰çš„ä½ç½®ä¿¡æ¯
            r'((?:(?!\n\n|\d{2}:\d{2}).)+)',
            re.DOTALL
        )

        for match in pattern.finditer(content):
            start_str = match.group(1)
            end_str = match.group(2)
            text = match.group(3).strip()
            text = re.sub(r'<[^>]+>', '', text)
            text = text.replace('\n', ' ').strip()
            if text:
                start_sec = self._timestamp_to_seconds(start_str)
                end_sec = self._timestamp_to_seconds(end_str)
                segments.append((start_sec, end_sec, text))

        return self._merge_and_format_segments(segments)

    def _parse_ass(self, content: str) -> str:
        """è§£æ ASS/SSA å­—å¹•"""
        segments = []
        # åŒ¹é… Dialogue è¡Œ
        pattern = re.compile(
            r'Dialogue:\s*\d+,'
            r'(\d+:\d{2}:\d{2}\.\d{2}),'
            r'(\d+:\d{2}:\d{2}\.\d{2}),'
            r'[^,]*,[^,]*,\d+,\d+,\d+,[^,]*,'
            r'(.*?)$',
            re.MULTILINE
        )

        for match in pattern.finditer(content):
            start_str = match.group(1)
            end_str = match.group(2)
            text = match.group(3).strip()
            # å»é™¤ ASS æ ·å¼æ ‡ç­¾
            text = re.sub(r'\{[^}]+\}', '', text)
            text = text.replace('\\N', ' ').replace('\\n', ' ')
            text = text.strip()
            if text:
                start_sec = self._timestamp_to_seconds(start_str)
                end_sec = self._timestamp_to_seconds(end_str)
                segments.append((start_sec, end_sec, text))

        segments.sort(key=lambda x: x[0])
        return self._merge_and_format_segments(segments)

    def _timestamp_to_seconds(self, timestamp: str) -> float:
        """å°†æ—¶é—´æˆ³å­—ç¬¦ä¸²è½¬æ¢ä¸ºç§’æ•°"""
        try:
            parts = timestamp.replace(',', '.').split(':')
            if len(parts) == 3:
                h, m, s = parts
                return int(h) * 3600 + int(m) * 60 + float(s)
            elif len(parts) == 2:
                m, s = parts
                return int(m) * 60 + float(s)
            else:
                return float(parts[0])
        except (ValueError, IndexError):
            return 0.0

    def _merge_and_format_segments(self, segments: list) -> str:
        """
        åˆå¹¶ç›¸é‚»çš„é‡å¤/è¿‘ä¼¼å­—å¹•æ®µï¼Œå¹¶æ ¼å¼åŒ–ä¸º Markdown
        
        å­—å¹•é€šå¸¸æ¯è¡Œå¾ˆçŸ­ä¸”æœ‰å¤§é‡é‡å ï¼Œéœ€è¦å»é‡åˆå¹¶
        """
        if not segments:
            return ""

        # å»é‡ï¼šç§»é™¤å®Œå…¨ç›¸åŒçš„è¿ç»­æ–‡æœ¬
        deduped = []
        prev_text = ""
        for start, end, text in segments:
            if text != prev_text:
                deduped.append((start, end, text))
                prev_text = text

        # æŒ‰æ—¶é—´æ®µåˆå¹¶ç›¸é‚»æ–‡æœ¬ï¼ˆæ¯30ç§’ä¸ºä¸€æ®µï¼‰
        merged = []
        current_start = deduped[0][0] if deduped else 0
        current_end = deduped[0][1] if deduped else 0
        current_texts = []
        merge_interval = 30.0  # æ¯30ç§’åˆå¹¶ä¸ºä¸€æ®µ

        for start, end, text in deduped:
            if start - current_start > merge_interval and current_texts:
                merged.append((current_start, current_end, ' '.join(current_texts)))
                current_start = start
                current_texts = []
            current_end = end
            current_texts.append(text)

        if current_texts:
            merged.append((current_start, current_end, ' '.join(current_texts)))

        # æ ¼å¼åŒ–ä¸º Markdown
        lines = []
        for start, end, text in merged:
            start_fmt = self._format_time_display(start)
            end_fmt = self._format_time_display(end)
            lines.append(f"**{start_fmt} - {end_fmt}**  ")
            lines.append(text)
            lines.append("")

        return '\n'.join(lines)

    def _format_time_display(self, seconds: float) -> str:
        """å°†ç§’æ•°æ ¼å¼åŒ–ä¸º HH:MM:SS æˆ– MM:SS"""
        hours = int(seconds // 3600)
        minutes = int((seconds % 3600) // 60)
        secs = int(seconds % 60)
        if hours > 0:
            return f"{hours:02d}:{minutes:02d}:{secs:02d}"
        else:
            return f"{minutes:02d}:{secs:02d}"

    async def _verify_and_fix_audio(
        self,
        audio_file: str,
        expected_duration: float,
        output_dir: Path,
        unique_id: str
    ) -> str:
        """
        éªŒè¯å¹¶ä¿®å¤éŸ³é¢‘æ–‡ä»¶æ—¶é•¿

        Args:
            audio_file: éŸ³é¢‘æ–‡ä»¶è·¯å¾„
            expected_duration: æœŸæœ›æ—¶é•¿ï¼ˆç§’ï¼‰
            output_dir: è¾“å‡ºç›®å½•
            unique_id: å”¯ä¸€æ ‡è¯†

        Returns:
            éŸ³é¢‘æ–‡ä»¶è·¯å¾„ï¼ˆå¯èƒ½æ˜¯ä¿®å¤åçš„æ–°æ–‡ä»¶ï¼‰
        """
        try:
            # è·å–å®é™…æ—¶é•¿
            probe_cmd = f"ffprobe -v error -show_entries format=duration -of default=noprint_wrappers=1:nokey=1 {shlex.quote(audio_file)}"
            out = subprocess.check_output(probe_cmd, shell=True).decode().strip()
            actual_duration = float(out) if out else 0.0
        except Exception:
            actual_duration = 0.0

        # æ£€æŸ¥æ—¶é•¿å·®å¼‚
        if expected_duration and actual_duration and abs(actual_duration - expected_duration) / expected_duration > 0.1:
            logger.warning(
                f"éŸ³é¢‘æ—¶é•¿å¼‚å¸¸ï¼ŒæœŸæœ›{expected_duration}sï¼Œå®é™…{actual_duration}sï¼Œå°è¯•é‡å°è£…ä¿®å¤â€¦"
            )
            try:
                fixed_path = str(output_dir / f"audio_{unique_id}_fixed.m4a")
                fix_cmd = f"ffmpeg -y -i {shlex.quote(audio_file)} -vn -c:a aac -b:a 160k -movflags +faststart {shlex.quote(fixed_path)}"
                subprocess.check_call(fix_cmd, shell=True)

                # ç”¨ä¿®å¤åçš„æ–‡ä»¶æ›¿æ¢
                audio_file = fixed_path

                # é‡æ–°æ¢æµ‹
                out2 = subprocess.check_output(
                    probe_cmd.replace(shlex.quote(audio_file.rsplit('.', 1)[0] + '.m4a'), shlex.quote(audio_file)),
                    shell=True
                ).decode().strip()
                actual_duration2 = float(out2) if out2 else 0.0
                logger.info(f"é‡å°è£…å®Œæˆï¼Œæ–°æ—¶é•¿â‰ˆ{actual_duration2:.2f}s")
            except Exception as e:
                logger.error(f"é‡å°è£…å¤±è´¥ï¼š{e}")

        return audio_file
